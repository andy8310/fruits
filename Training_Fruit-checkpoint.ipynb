{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras as kr\n",
    "kr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import keras.models\n",
    "import sklearn.model_selection as sk\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Activation, Flatten,add\n",
    "from keras.layers import Input,Dense,Dropout,BatchNormalization,Convolution2D,MaxPooling2D,AveragePooling2D,Concatenate,ZeroPadding2D,GlobalAveragePooling2D\n",
    "from keras.layers import Flatten, Activation, Conv2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model,load_model\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model,np_utils\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.metrics as metric\n",
    "from keras.optimizers import SGD\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "train_data='D:\\\\fruit\\\\train\\\\'\n",
    "vaildation_data='D:\\\\fruit\\\\vaildation\\\\'\n",
    "\n",
    "#C:\\\\Users\\\\star\\\\GoogleNetV4_sex_20190621\\\\traindata\n",
    "#train_data='D:\\data\\sex\\ctrain\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testdata():    \n",
    "#     test_imgs=[]\n",
    "#     for i in tqdm(os.listdir(test_data)):\n",
    "#         if i[len(i)-1]=='g':\n",
    "#             #print(i)\n",
    "#             test_img=cv2.imread(test_data+i, cv2.IMREAD_COLOR)\n",
    "#             test_imgs=cv2.resize(test_img,(299,299))\n",
    "#     return test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing_images = testdata()\n",
    "# te_img_data = np.array([i for i in testing_images]).reshape(-1,299,299,3)\n",
    "# print(te_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imglabel(nimg):\n",
    "    if nimg[0]=='a' and nimg[1]=='p':\n",
    "        return np.array([0,0,1])\n",
    "    elif nimg[0]=='b' and nimg[1]=='a':\n",
    "        return np.array([0,1,0])\n",
    "    elif nimg[0]=='o' and nimg[1]=='r':\n",
    "        return np.array([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaildationdata():\n",
    "    vaildation_imgs=[]\n",
    "    for i in tqdm(os.listdir(vaildation_data)):\n",
    "        if i[len(i)-1]=='g':\n",
    "            #print(i)\n",
    "            vaoimg=cv2.imread(vaildation_data+i, cv2.IMREAD_COLOR)\n",
    "            #print(i)\n",
    "            #height, width, channels = img.shape\n",
    "            vaimg=cv2.resize(vaoimg,(299,299))\n",
    "            #neimg = cv2.resize(oimg, (224, 224))\n",
    "            #b, g, r = cv2.split(img)\n",
    "            #b = 255 - b\n",
    "            #g = 255 - g\n",
    "            #r = 255 - r\n",
    "            #neimg[:, :, 0] = b\n",
    "            #neimg[:, :, 1] = g\n",
    "            #neimg[:, :, 2] = r\n",
    "            vaildation_imgs.append([np.array(vaimg),imglabel(i)])\n",
    "            #flip_1 = np.fliplr(img)\n",
    "            #flip_2 = np.flipud(img)\n",
    "            #train_imgs.append([np.array(flip_1),imglabel(i)])\n",
    "            #train_imgs.append([np.array(flip_2),imglabel(i)])\n",
    "    return vaildation_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 334.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vaildation_images = vaildationdata()\n",
    "va_img_data = np.array([i[0] for i in vaildation_images]).reshape(-1,299,299,3)\n",
    "va_lbl_data = np.array([i[1] for i in vaildation_images])\n",
    "print(va_lbl_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindata():\n",
    "    train_imgs=[]\n",
    "    for i in tqdm(os.listdir(train_data)):\n",
    "        if i[len(i)-1]=='g':\n",
    "            #print(i)\n",
    "            oimg=cv2.imread(train_data+i, cv2.IMREAD_COLOR)\n",
    "            #print(i)\n",
    "            #height, width, channels = img.shape\n",
    "            img=cv2.resize(oimg,(299,299))\n",
    "            #neimg = cv2.resize(oimg, (224, 224))\n",
    "            #b, g, r = cv2.split(img)\n",
    "            #b = 255 - b\n",
    "            #g = 255 - g\n",
    "            #r = 255 - r\n",
    "            #neimg[:, :, 0] = b\n",
    "            #neimg[:, :, 1] = g\n",
    "            #neimg[:, :, 2] = r\n",
    "            train_imgs.append([np.array(img),imglabel(i)])\n",
    "            #flip_1 = np.fliplr(img)\n",
    "            #flip_2 = np.flipud(img)\n",
    "            #train_imgs.append([np.array(flip_1),imglabel(i)])\n",
    "            #train_imgs.append([np.array(flip_2),imglabel(i)])\n",
    "    return train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 549.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_images = traindata()\n",
    "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,299,299,3)\n",
    "tr_lbl_data = np.array([i[1] for i in training_images])\n",
    "print(tr_lbl_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立CNN(googlNet)模型，基於inception_4的模塊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_BLOCK_COUNT = 0  # 用来命名计数卷积编号\n",
    "INCEPTION_A_COUNT = 0\n",
    "INCEPTION_B_COUNT = 0\n",
    "INCEPTION_C_COUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, nb_filters, nb_row, nb_col, strides=(1, 1), padding='same', use_bias=False):\n",
    "    global CONV_BLOCK_COUNT\n",
    "    CONV_BLOCK_COUNT += 1\n",
    "    with K.name_scope('conv_block_'+str(CONV_BLOCK_COUNT)):\n",
    "        x = Conv2D(filters=nb_filters,\n",
    "                   kernel_size=(nb_row, nb_col),\n",
    "                   strides=strides,\n",
    "                   padding=padding,\n",
    "                   use_bias=use_bias)(x)\n",
    "        x = BatchNormalization(axis=-1, momentum=0.9, scale=False)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(x_input):\n",
    "    with K.name_scope('stem'):\n",
    "        x = conv_block(x_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "        x = conv_block(x, 32, 3, 3, padding='valid')\n",
    "        x = conv_block(x, 64, 3, 3)\n",
    " \n",
    "        x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "        x2 = conv_block(x, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        x = concatenate([x1, x2], axis=-1)\n",
    " \n",
    "        x1 = conv_block(x, 64, 1, 1)\n",
    "        x1 = conv_block(x1, 96, 3, 3, padding='valid')\n",
    " \n",
    "        x2 = conv_block(x, 64, 1, 1)\n",
    "        x2 = conv_block(x2, 64, 7, 1)\n",
    "        x2 = conv_block(x2, 64, 1, 7)\n",
    "        x2 = conv_block(x2, 96, 3, 3, padding='valid')\n",
    " \n",
    "        x = concatenate([x1, x2], axis=-1)\n",
    " \n",
    "        x1 = conv_block(x, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "        x2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    " \n",
    "        merged_vector = concatenate([x1, x2], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_A(x_input):\n",
    "    \"\"\"35*35 卷积块\"\"\"\n",
    "    global INCEPTION_A_COUNT\n",
    "    INCEPTION_A_COUNT += 1\n",
    "    with K.name_scope('inception_A' + str(INCEPTION_A_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)  # 35 * 35 * 192\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 96, 1, 1)  # 35 * 35 * 96\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 96, 1, 1)  # 35 * 35 * 96\n",
    " \n",
    "        conv1x1_3x3 = conv_block(x_input, 64, 1, 1)  # 35 * 35 * 64\n",
    "        conv1x1_3x3 = conv_block(conv1x1_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    " \n",
    "        conv3x3_3x3 = conv_block(x_input, 64, 1, 1)  # 35 * 35 * 64\n",
    "        conv3x3_3x3 = conv_block(conv3x3_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    "        conv3x3_3x3 = conv_block(conv3x3_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv1x1_3x3, conv3x3_3x3], axis=-1)  # 35 * 35 * 384\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_B(x_input):\n",
    "    \"\"\"17*17 卷积块\"\"\"\n",
    "    global INCEPTION_B_COUNT\n",
    "    INCEPTION_B_COUNT += 1\n",
    "    with K.name_scope('inception_B' + str(INCEPTION_B_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 128, 1, 1)\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 384, 1, 1)\n",
    " \n",
    "        conv1x7_1x7 = conv_block(x_input, 192, 1, 1)\n",
    "        conv1x7_1x7 = conv_block(conv1x7_1x7, 224, 1, 7)\n",
    "        conv1x7_1x7 = conv_block(conv1x7_1x7, 256, 1, 7)\n",
    " \n",
    "        conv2_1x7_7x1 = conv_block(x_input, 192, 1, 1)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 192, 1, 7)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 224, 7, 1)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 224, 1, 7)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 256, 7, 1)\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv1x7_1x7, conv2_1x7_7x1], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_C(x_input):\n",
    "    \"\"\"8*8 卷积块\"\"\"\n",
    "    global INCEPTION_C_COUNT\n",
    "    INCEPTION_C_COUNT += 1\n",
    "    with K.name_scope('Inception_C' + str(INCEPTION_C_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 256, 1, 1)\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 256, 1, 1)\n",
    " \n",
    "        # 用 1x3 和 3x1 替代 3x3\n",
    "        conv3x3_1x1 = conv_block(x_input, 384, 1, 1)\n",
    "        conv3x3_1 = conv_block(conv3x3_1x1, 256, 1, 3)\n",
    "        conv3x3_2 = conv_block(conv3x3_1x1, 256, 3, 1)\n",
    " \n",
    "        conv2_3x3_1x1 = conv_block(x_input, 384, 1, 1)\n",
    "        conv2_3x3_1x1 = conv_block(conv2_3x3_1x1, 448, 1, 3)\n",
    "        conv2_3x3_1x1 = conv_block(conv2_3x3_1x1, 512, 3, 1)\n",
    "        conv2_3x3_1x1_1 = conv_block(conv2_3x3_1x1, 256, 3, 1)\n",
    "        conv2_3x3_1x1_2 = conv_block(conv2_3x3_1x1, 256, 1, 3)\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv3x3_1, conv3x3_2, conv2_3x3_1x1_1, conv2_3x3_1x1_2], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_A(x_input, k=192, l=224, m=256, n=384):\n",
    "    with K.name_scope('Reduction_A'):\n",
    "        \"\"\"Architecture of a 35 * 35 to 17 * 17 Reduction_A block.\"\"\"\n",
    "        maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x_input)\n",
    " \n",
    "        conv3x3 = conv_block(x_input, n, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        conv2_3x3 = conv_block(x_input, k, 1, 1)\n",
    "        conv2_3x3 = conv_block(conv2_3x3, l, 3, 3)\n",
    "        conv2_3x3 = conv_block(conv2_3x3, m, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        merged_vector = concatenate([maxpool, conv3x3, conv2_3x3], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_B(x_input):\n",
    "    \"\"\"Architecture of a 17 * 17 to 8 * 8 Reduction_B block.\"\"\"\n",
    "    with K.name_scope('Reduction_B'):\n",
    "        maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x_input)\n",
    " \n",
    "        conv3x3 = conv_block(x_input, 192, 1, 1)\n",
    "        conv3x3 = conv_block(conv3x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        conv1x7_7x1_3x3 = conv_block(x_input, 256, 1, 1)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 256, 1, 7)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 320, 7, 1)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 320, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        merged_vector = concatenate([maxpool, conv3x3, conv1x7_7x1_3x3], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v4_backbone(nb_classes=3, load_weights=True):\n",
    "    x_input = Input(shape=(299, 299, 3))\n",
    "    # Stem\n",
    "    x = stem(x_input)  # 35 x 35 x 384\n",
    "    # 4 x Inception_A\n",
    "    for i in range(4):\n",
    "        x = inception_A(x)  # 35 x 35 x 384\n",
    "    # Reduction_A\n",
    "    x = reduction_A(x, k=192, l=224, m=256, n=384)  # 17 x 17 x 1024\n",
    "    # 7 x Inception_B\n",
    "    for i in range(7):\n",
    "        x = inception_B(x)  # 17 x 17 x1024\n",
    "    # Reduction_B\n",
    "    x = reduction_B(x)  # 8 x 8 x 1536\n",
    "    # Average Pooling\n",
    "    x = AveragePooling2D(pool_size=(8, 8))(x)  # 1536\n",
    "    # dropout\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)  # 1536\n",
    "    # 全连接层\n",
    "    x = Dense(units=nb_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x, name='Inception-V4')\n",
    "    model.save('googlenetV4_classification_fruit.h5')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將model存下來(per Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_path ='D:\\\\fruit\\\\model\\\\'\n",
    "\n",
    "model_name = \"checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(model_path,model_name),\n",
    "                             monitor='val_acc',verbose=1,save_best_only=False, save_weights_only=False,\n",
    "                             mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Inception-V4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)             (None, 149, 149, 32) 864         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchN (None, 149, 149, 32) 96          conv2d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_596 (Activation)     (None, 149, 149, 32) 0           batch_normalization_596[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)             (None, 147, 147, 32) 9216        activation_596[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchN (None, 147, 147, 32) 96          conv2d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_597 (Activation)     (None, 147, 147, 32) 0           batch_normalization_597[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)             (None, 147, 147, 64) 18432       activation_597[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchN (None, 147, 147, 64) 192         conv2d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_598 (Activation)     (None, 147, 147, 64) 0           batch_normalization_598[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)             (None, 73, 73, 96)   55296       activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchN (None, 73, 73, 96)   288         conv2d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 73, 73, 64)   0           activation_598[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_599 (Activation)     (None, 73, 73, 96)   0           batch_normalization_599[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 73, 73, 160)  0           max_pooling2d_21[0][0]           \n",
      "                                                                 activation_599[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)             (None, 73, 73, 64)   10240       concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchN (None, 73, 73, 64)   192         conv2d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_602 (Activation)     (None, 73, 73, 64)   0           batch_normalization_602[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)             (None, 73, 73, 64)   28672       activation_602[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchN (None, 73, 73, 64)   192         conv2d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_603 (Activation)     (None, 73, 73, 64)   0           batch_normalization_603[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)             (None, 73, 73, 64)   10240       concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)             (None, 73, 73, 64)   28672       activation_603[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchN (None, 73, 73, 64)   192         conv2d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchN (None, 73, 73, 64)   192         conv2d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_600 (Activation)     (None, 73, 73, 64)   0           batch_normalization_600[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_604 (Activation)     (None, 73, 73, 64)   0           batch_normalization_604[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)             (None, 71, 71, 96)   55296       activation_600[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)             (None, 71, 71, 96)   55296       activation_604[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchN (None, 71, 71, 96)   288         conv2d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchN (None, 71, 71, 96)   288         conv2d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_601 (Activation)     (None, 71, 71, 96)   0           batch_normalization_601[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_605 (Activation)     (None, 71, 71, 96)   0           batch_normalization_605[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 71, 71, 192)  0           activation_601[0][0]             \n",
      "                                                                 activation_605[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)             (None, 35, 35, 192)  331776      concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchN (None, 35, 35, 192)  576         conv2d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_606 (Activation)     (None, 35, 35, 192)  0           batch_normalization_606[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 35, 35, 192)  0           concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 35, 35, 384)  0           activation_606[0][0]             \n",
      "                                                                 max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 35, 35, 64)   192         conv2d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_611 (Activation)     (None, 35, 35, 64)   0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)             (None, 35, 35, 96)   55296       activation_611[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchN (None, 35, 35, 64)   192         conv2d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 35, 35, 96)   288         conv2d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePo (None, 35, 35, 384)  0           concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_609 (Activation)     (None, 35, 35, 64)   0           batch_normalization_609[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_612 (Activation)     (None, 35, 35, 96)   0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_61[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)             (None, 35, 35, 96)   55296       activation_609[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)             (None, 35, 35, 96)   82944       activation_612[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchN (None, 35, 35, 96)   288         conv2d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchN (None, 35, 35, 96)   288         conv2d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 35, 35, 96)   288         conv2d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 35, 35, 96)   288         conv2d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_607 (Activation)     (None, 35, 35, 96)   0           batch_normalization_607[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_608 (Activation)     (None, 35, 35, 96)   0           batch_normalization_608[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_610 (Activation)     (None, 35, 35, 96)   0           batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_613 (Activation)     (None, 35, 35, 96)   0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 35, 35, 384)  0           activation_607[0][0]             \n",
      "                                                                 activation_608[0][0]             \n",
      "                                                                 activation_610[0][0]             \n",
      "                                                                 activation_613[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 35, 35, 64)   192         conv2d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_618 (Activation)     (None, 35, 35, 64)   0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)             (None, 35, 35, 96)   55296       activation_618[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 35, 35, 64)   192         conv2d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 35, 35, 96)   288         conv2d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePo (None, 35, 35, 384)  0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_616 (Activation)     (None, 35, 35, 64)   0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_619 (Activation)     (None, 35, 35, 96)   0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_62[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)             (None, 35, 35, 96)   55296       activation_616[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)             (None, 35, 35, 96)   82944       activation_619[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 35, 35, 96)   288         conv2d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 35, 35, 96)   288         conv2d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 35, 35, 96)   288         conv2d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 35, 35, 96)   288         conv2d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_614 (Activation)     (None, 35, 35, 96)   0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_615 (Activation)     (None, 35, 35, 96)   0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_617 (Activation)     (None, 35, 35, 96)   0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_620 (Activation)     (None, 35, 35, 96)   0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 35, 35, 384)  0           activation_614[0][0]             \n",
      "                                                                 activation_615[0][0]             \n",
      "                                                                 activation_617[0][0]             \n",
      "                                                                 activation_620[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 35, 35, 64)   192         conv2d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_625 (Activation)     (None, 35, 35, 64)   0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)             (None, 35, 35, 96)   55296       activation_625[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 35, 35, 64)   192         conv2d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 35, 35, 96)   288         conv2d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_63 (AveragePo (None, 35, 35, 384)  0           concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_623 (Activation)     (None, 35, 35, 64)   0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_626 (Activation)     (None, 35, 35, 96)   0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_63[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)             (None, 35, 35, 96)   55296       activation_623[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)             (None, 35, 35, 96)   82944       activation_626[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 35, 35, 96)   288         conv2d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 35, 35, 96)   288         conv2d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 35, 35, 96)   288         conv2d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 35, 35, 96)   288         conv2d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_621 (Activation)     (None, 35, 35, 96)   0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_622 (Activation)     (None, 35, 35, 96)   0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_624 (Activation)     (None, 35, 35, 96)   0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_627 (Activation)     (None, 35, 35, 96)   0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 35, 35, 384)  0           activation_621[0][0]             \n",
      "                                                                 activation_622[0][0]             \n",
      "                                                                 activation_624[0][0]             \n",
      "                                                                 activation_627[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchN (None, 35, 35, 64)   192         conv2d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_632 (Activation)     (None, 35, 35, 64)   0           batch_normalization_632[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)             (None, 35, 35, 64)   24576       concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)             (None, 35, 35, 96)   55296       activation_632[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 35, 35, 64)   192         conv2d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchN (None, 35, 35, 96)   288         conv2d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_64 (AveragePo (None, 35, 35, 384)  0           concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_630 (Activation)     (None, 35, 35, 64)   0           batch_normalization_630[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_633 (Activation)     (None, 35, 35, 96)   0           batch_normalization_633[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)             (None, 35, 35, 96)   36864       average_pooling2d_64[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)             (None, 35, 35, 96)   36864       concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)             (None, 35, 35, 96)   55296       activation_630[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)             (None, 35, 35, 96)   82944       activation_633[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 35, 35, 96)   288         conv2d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 35, 35, 96)   288         conv2d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchN (None, 35, 35, 96)   288         conv2d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchN (None, 35, 35, 96)   288         conv2d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_628 (Activation)     (None, 35, 35, 96)   0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_629 (Activation)     (None, 35, 35, 96)   0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_631 (Activation)     (None, 35, 35, 96)   0           batch_normalization_631[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_634 (Activation)     (None, 35, 35, 96)   0           batch_normalization_634[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 35, 35, 384)  0           activation_628[0][0]             \n",
      "                                                                 activation_629[0][0]             \n",
      "                                                                 activation_631[0][0]             \n",
      "                                                                 activation_634[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)             (None, 35, 35, 192)  73728       concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchN (None, 35, 35, 192)  576         conv2d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_636 (Activation)     (None, 35, 35, 192)  0           batch_normalization_636[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)             (None, 35, 35, 224)  387072      activation_636[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchN (None, 35, 35, 224)  672         conv2d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_637 (Activation)     (None, 35, 35, 224)  0           batch_normalization_637[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)             (None, 17, 17, 384)  1327104     concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)             (None, 17, 17, 256)  516096      activation_637[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchN (None, 17, 17, 384)  1152        conv2d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchN (None, 17, 17, 256)  768         conv2d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 17, 17, 384)  0           concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_635 (Activation)     (None, 17, 17, 384)  0           batch_normalization_635[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_638 (Activation)     (None, 17, 17, 256)  0           batch_normalization_638[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 17, 17, 1024) 0           max_pooling2d_23[0][0]           \n",
      "                                                                 activation_635[0][0]             \n",
      "                                                                 activation_638[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchN (None, 17, 17, 192)  576         conv2d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_644 (Activation)     (None, 17, 17, 192)  0           batch_normalization_644[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)             (None, 17, 17, 192)  258048      activation_644[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchN (None, 17, 17, 192)  576         conv2d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_645 (Activation)     (None, 17, 17, 192)  0           batch_normalization_645[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)             (None, 17, 17, 224)  301056      activation_645[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchN (None, 17, 17, 192)  576         conv2d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 17, 17, 224)  672         conv2d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_641 (Activation)     (None, 17, 17, 192)  0           batch_normalization_641[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_646 (Activation)     (None, 17, 17, 224)  0           batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)             (None, 17, 17, 224)  301056      activation_641[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)             (None, 17, 17, 224)  351232      activation_646[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchN (None, 17, 17, 224)  672         conv2d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 17, 17, 224)  672         conv2d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_65 (AveragePo (None, 17, 17, 1024) 0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_642 (Activation)     (None, 17, 17, 224)  0           batch_normalization_642[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_647 (Activation)     (None, 17, 17, 224)  0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_65[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)             (None, 17, 17, 256)  401408      activation_642[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)             (None, 17, 17, 256)  401408      activation_647[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchN (None, 17, 17, 128)  384         conv2d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchN (None, 17, 17, 384)  1152        conv2d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchN (None, 17, 17, 256)  768         conv2d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 17, 17, 256)  768         conv2d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_639 (Activation)     (None, 17, 17, 128)  0           batch_normalization_639[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_640 (Activation)     (None, 17, 17, 384)  0           batch_normalization_640[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_643 (Activation)     (None, 17, 17, 256)  0           batch_normalization_643[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_648 (Activation)     (None, 17, 17, 256)  0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 17, 17, 1024) 0           activation_639[0][0]             \n",
      "                                                                 activation_640[0][0]             \n",
      "                                                                 activation_643[0][0]             \n",
      "                                                                 activation_648[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 17, 17, 192)  576         conv2d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_654 (Activation)     (None, 17, 17, 192)  0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)             (None, 17, 17, 192)  258048      activation_654[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 17, 17, 192)  576         conv2d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_655 (Activation)     (None, 17, 17, 192)  0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)             (None, 17, 17, 224)  301056      activation_655[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 17, 17, 192)  576         conv2d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 17, 17, 224)  672         conv2d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_651 (Activation)     (None, 17, 17, 192)  0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_656 (Activation)     (None, 17, 17, 224)  0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)             (None, 17, 17, 224)  301056      activation_651[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)             (None, 17, 17, 224)  351232      activation_656[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 17, 17, 224)  672         conv2d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 17, 17, 224)  672         conv2d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_66 (AveragePo (None, 17, 17, 1024) 0           concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_652 (Activation)     (None, 17, 17, 224)  0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_657 (Activation)     (None, 17, 17, 224)  0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_66[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)             (None, 17, 17, 256)  401408      activation_652[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)             (None, 17, 17, 256)  401408      activation_657[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 17, 17, 128)  384         conv2d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 17, 17, 384)  1152        conv2d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 17, 17, 256)  768         conv2d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 17, 17, 256)  768         conv2d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_649 (Activation)     (None, 17, 17, 128)  0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_650 (Activation)     (None, 17, 17, 384)  0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_653 (Activation)     (None, 17, 17, 256)  0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_658 (Activation)     (None, 17, 17, 256)  0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 17, 17, 1024) 0           activation_649[0][0]             \n",
      "                                                                 activation_650[0][0]             \n",
      "                                                                 activation_653[0][0]             \n",
      "                                                                 activation_658[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_664 (BatchN (None, 17, 17, 192)  576         conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_664 (Activation)     (None, 17, 17, 192)  0           batch_normalization_664[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 17, 17, 192)  258048      activation_664[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_665 (BatchN (None, 17, 17, 192)  576         conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_665 (Activation)     (None, 17, 17, 192)  0           batch_normalization_665[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 17, 17, 224)  301056      activation_665[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_661 (BatchN (None, 17, 17, 192)  576         conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_666 (BatchN (None, 17, 17, 224)  672         conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_661 (Activation)     (None, 17, 17, 192)  0           batch_normalization_661[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_666 (Activation)     (None, 17, 17, 224)  0           batch_normalization_666[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 17, 17, 224)  301056      activation_661[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 17, 17, 224)  351232      activation_666[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_662 (BatchN (None, 17, 17, 224)  672         conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_667 (BatchN (None, 17, 17, 224)  672         conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_67 (AveragePo (None, 17, 17, 1024) 0           concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_662 (Activation)     (None, 17, 17, 224)  0           batch_normalization_662[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_667 (Activation)     (None, 17, 17, 224)  0           batch_normalization_667[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_659 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_67[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_660 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 17, 17, 256)  401408      activation_662[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 17, 17, 256)  401408      activation_667[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_659 (BatchN (None, 17, 17, 128)  384         conv2d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_660 (BatchN (None, 17, 17, 384)  1152        conv2d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_663 (BatchN (None, 17, 17, 256)  768         conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_668 (BatchN (None, 17, 17, 256)  768         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_659 (Activation)     (None, 17, 17, 128)  0           batch_normalization_659[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_660 (Activation)     (None, 17, 17, 384)  0           batch_normalization_660[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_663 (Activation)     (None, 17, 17, 256)  0           batch_normalization_663[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_668 (Activation)     (None, 17, 17, 256)  0           batch_normalization_668[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 17, 17, 1024) 0           activation_659[0][0]             \n",
      "                                                                 activation_660[0][0]             \n",
      "                                                                 activation_663[0][0]             \n",
      "                                                                 activation_668[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 17, 17, 192)  576         conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_674 (Activation)     (None, 17, 17, 192)  0           batch_normalization_674[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 17, 17, 192)  258048      activation_674[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_675 (BatchN (None, 17, 17, 192)  576         conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_675 (Activation)     (None, 17, 17, 192)  0           batch_normalization_675[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 17, 17, 224)  301056      activation_675[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 17, 17, 192)  576         conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_676 (BatchN (None, 17, 17, 224)  672         conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_671 (Activation)     (None, 17, 17, 192)  0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_676 (Activation)     (None, 17, 17, 224)  0           batch_normalization_676[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 17, 17, 224)  301056      activation_671[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 17, 17, 224)  351232      activation_676[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 17, 17, 224)  672         conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_677 (BatchN (None, 17, 17, 224)  672         conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_68 (AveragePo (None, 17, 17, 1024) 0           concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_672 (Activation)     (None, 17, 17, 224)  0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_677 (Activation)     (None, 17, 17, 224)  0           batch_normalization_677[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_68[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 17, 17, 256)  401408      activation_672[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 17, 17, 256)  401408      activation_677[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_669 (BatchN (None, 17, 17, 128)  384         conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 17, 17, 384)  1152        conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 17, 17, 256)  768         conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_678 (BatchN (None, 17, 17, 256)  768         conv2d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_669 (Activation)     (None, 17, 17, 128)  0           batch_normalization_669[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_670 (Activation)     (None, 17, 17, 384)  0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_673 (Activation)     (None, 17, 17, 256)  0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_678 (Activation)     (None, 17, 17, 256)  0           batch_normalization_678[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 17, 17, 1024) 0           activation_669[0][0]             \n",
      "                                                                 activation_670[0][0]             \n",
      "                                                                 activation_673[0][0]             \n",
      "                                                                 activation_678[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_684 (BatchN (None, 17, 17, 192)  576         conv2d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_684 (Activation)     (None, 17, 17, 192)  0           batch_normalization_684[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 17, 17, 192)  258048      activation_684[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_685 (BatchN (None, 17, 17, 192)  576         conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_685 (Activation)     (None, 17, 17, 192)  0           batch_normalization_685[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 17, 17, 224)  301056      activation_685[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_681 (BatchN (None, 17, 17, 192)  576         conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_686 (BatchN (None, 17, 17, 224)  672         conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_681 (Activation)     (None, 17, 17, 192)  0           batch_normalization_681[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_686 (Activation)     (None, 17, 17, 224)  0           batch_normalization_686[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_682 (Conv2D)             (None, 17, 17, 224)  301056      activation_681[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 17, 17, 224)  351232      activation_686[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_682 (BatchN (None, 17, 17, 224)  672         conv2d_682[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_687 (BatchN (None, 17, 17, 224)  672         conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_69 (AveragePo (None, 17, 17, 1024) 0           concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_682 (Activation)     (None, 17, 17, 224)  0           batch_normalization_682[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_687 (Activation)     (None, 17, 17, 224)  0           batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_69[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 17, 17, 256)  401408      activation_682[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 17, 17, 256)  401408      activation_687[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_679 (BatchN (None, 17, 17, 128)  384         conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_680 (BatchN (None, 17, 17, 384)  1152        conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_683 (BatchN (None, 17, 17, 256)  768         conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_688 (BatchN (None, 17, 17, 256)  768         conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_679 (Activation)     (None, 17, 17, 128)  0           batch_normalization_679[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_680 (Activation)     (None, 17, 17, 384)  0           batch_normalization_680[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_683 (Activation)     (None, 17, 17, 256)  0           batch_normalization_683[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_688 (Activation)     (None, 17, 17, 256)  0           batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 17, 17, 1024) 0           activation_679[0][0]             \n",
      "                                                                 activation_680[0][0]             \n",
      "                                                                 activation_683[0][0]             \n",
      "                                                                 activation_688[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_694 (BatchN (None, 17, 17, 192)  576         conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_694 (Activation)     (None, 17, 17, 192)  0           batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 17, 17, 192)  258048      activation_694[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_695 (BatchN (None, 17, 17, 192)  576         conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_695 (Activation)     (None, 17, 17, 192)  0           batch_normalization_695[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 17, 17, 224)  301056      activation_695[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_691 (BatchN (None, 17, 17, 192)  576         conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_696 (BatchN (None, 17, 17, 224)  672         conv2d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_691 (Activation)     (None, 17, 17, 192)  0           batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_696 (Activation)     (None, 17, 17, 224)  0           batch_normalization_696[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 17, 17, 224)  301056      activation_691[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 17, 17, 224)  351232      activation_696[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_692 (BatchN (None, 17, 17, 224)  672         conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_697 (BatchN (None, 17, 17, 224)  672         conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_70 (AveragePo (None, 17, 17, 1024) 0           concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_692 (Activation)     (None, 17, 17, 224)  0           batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_697 (Activation)     (None, 17, 17, 224)  0           batch_normalization_697[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_70[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 17, 17, 256)  401408      activation_692[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 17, 17, 256)  401408      activation_697[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_689 (BatchN (None, 17, 17, 128)  384         conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_690 (BatchN (None, 17, 17, 384)  1152        conv2d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_693 (BatchN (None, 17, 17, 256)  768         conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_698 (BatchN (None, 17, 17, 256)  768         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_689 (Activation)     (None, 17, 17, 128)  0           batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_690 (Activation)     (None, 17, 17, 384)  0           batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_693 (Activation)     (None, 17, 17, 256)  0           batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_698 (Activation)     (None, 17, 17, 256)  0           batch_normalization_698[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 17, 17, 1024) 0           activation_689[0][0]             \n",
      "                                                                 activation_690[0][0]             \n",
      "                                                                 activation_693[0][0]             \n",
      "                                                                 activation_698[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_704 (BatchN (None, 17, 17, 192)  576         conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_704 (Activation)     (None, 17, 17, 192)  0           batch_normalization_704[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 17, 17, 192)  258048      activation_704[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_705 (BatchN (None, 17, 17, 192)  576         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_705 (Activation)     (None, 17, 17, 192)  0           batch_normalization_705[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_701 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 17, 17, 224)  301056      activation_705[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_701 (BatchN (None, 17, 17, 192)  576         conv2d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_706 (BatchN (None, 17, 17, 224)  672         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_701 (Activation)     (None, 17, 17, 192)  0           batch_normalization_701[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_706 (Activation)     (None, 17, 17, 224)  0           batch_normalization_706[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 17, 17, 224)  301056      activation_701[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 17, 17, 224)  351232      activation_706[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_702 (BatchN (None, 17, 17, 224)  672         conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_707 (BatchN (None, 17, 17, 224)  672         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_71 (AveragePo (None, 17, 17, 1024) 0           concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_702 (Activation)     (None, 17, 17, 224)  0           batch_normalization_702[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_707 (Activation)     (None, 17, 17, 224)  0           batch_normalization_707[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_71[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 17, 17, 256)  401408      activation_702[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 17, 17, 256)  401408      activation_707[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_699 (BatchN (None, 17, 17, 128)  384         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_700 (BatchN (None, 17, 17, 384)  1152        conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_703 (BatchN (None, 17, 17, 256)  768         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_708 (BatchN (None, 17, 17, 256)  768         conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_699 (Activation)     (None, 17, 17, 128)  0           batch_normalization_699[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_700 (Activation)     (None, 17, 17, 384)  0           batch_normalization_700[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_703 (Activation)     (None, 17, 17, 256)  0           batch_normalization_703[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_708 (Activation)     (None, 17, 17, 256)  0           batch_normalization_708[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 17, 17, 1024) 0           activation_699[0][0]             \n",
      "                                                                 activation_700[0][0]             \n",
      "                                                                 activation_703[0][0]             \n",
      "                                                                 activation_708[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 17, 17, 256)  262144      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_711 (BatchN (None, 17, 17, 256)  768         conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 17, 17, 256)  0           batch_normalization_711[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 17, 17, 256)  458752      activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_712 (BatchN (None, 17, 17, 256)  768         conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 17, 17, 256)  0           batch_normalization_712[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 17, 17, 320)  573440      activation_712[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_709 (BatchN (None, 17, 17, 192)  576         conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_713 (BatchN (None, 17, 17, 320)  960         conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_709 (Activation)     (None, 17, 17, 192)  0           batch_normalization_709[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 17, 17, 320)  0           batch_normalization_713[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 8, 8, 192)    331776      activation_709[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 8, 8, 320)    921600      activation_713[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_710 (BatchN (None, 8, 8, 192)    576         conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_714 (BatchN (None, 8, 8, 320)    960         conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 8, 8, 1024)   0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 8, 8, 192)    0           batch_normalization_710[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 8, 8, 320)    0           batch_normalization_714[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 8, 8, 1536)   0           max_pooling2d_24[0][0]           \n",
      "                                                                 activation_710[0][0]             \n",
      "                                                                 activation_714[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_72 (AveragePo (None, 1, 1, 1536)   0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1, 1, 1536)   0           average_pooling2d_72[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 1536)         0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            4611        flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,509,955\n",
      "Trainable params: 27,466,371\n",
      "Non-trainable params: 43,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17 samples, validate on 3 samples\n",
      "Epoch 1/150\n"
     ]
    }
   ],
   "source": [
    "model = inception_v4_backbone()\n",
    "plot_model(model, 'inceptionv4_classification_fruit.png', show_shapes=True)\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0, nesterov=False) #decay：每次更新後，學習速率隨之衰減的比率\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.summary();\n",
    "#history = model.fit(x=tr_img_data, y=tr_lbl_data, batch_size=32, epochs=150,verbose=2,shuffle=True,validation_split=0.1)\n",
    "history = model.fit(x=tr_img_data, y=tr_lbl_data, batch_size=32, epochs=150,verbose=2,shuffle=True,validation_data=(va_img_data,va_lbl_data))\n",
    "model.save('googlenetV4_classification_ORI_fruit.h5')\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(va_img_data, va_lbl_data, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "  \n",
    "def isDisplayAvl():  \n",
    "    return 'DISPLAY' in os.environ.keys()  \n",
    "  \n",
    "import matplotlib.pyplot as plt  \n",
    "def plot_image(image):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(2,2)  \n",
    "    plt.imshow(image, cmap='binary')  \n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "def show_train_history(history, tr_img_data, te_img_data):  \n",
    "    plt.plot(history.history[tr_img_data])  \n",
    "    plt.plot(history.history[te_img_data])  \n",
    "    plt.title('Train History')  \n",
    "    plt.ylabel(tr_img_data)  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['train', 'validation'], loc='upper left')  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用函數 show_train_history 顯示 accuracy 在 train 與 evaluation 的差異\n",
    "#loss 在 train 與 evaluation 的差異\n",
    "from keras.utils import *  \n",
    "if isDisplayAvl():  \n",
    "    show_train_history(history, 'acc', 'val_acc')\n",
    "    show_train_history(history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(history, 'acc', 'val_acc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_train_history(history, 'loss', 'val_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kfold =KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "tr_cvscores = []\n",
    "test_cvscores = []\n",
    "for ktrain, ktest in kfold.split(tr_img_data, tr_lbl_data):\n",
    "    #history = model.fit(x=tr_img_data[ktrain], y=tr_lbl_data[ktrain], batch_size=16, epochs=100,verbose=2,validation_split=0.2)\n",
    "    #model.save(str(times)+'_mosq-res34.h5')\n",
    "    #times=times+1\n",
    "    tr_score, tr_acc = model.evaluate(tr_img_data[ktrain],tr_lbl_data[ktrain])\n",
    "    print('Training score:', tr_score)\n",
    "    print('Training accuracy:', tr_acc)\n",
    "    tr_cvscores.append(tr_acc * 100)\n",
    "    test_score, test_acc = model.evaluate(tr_img_data[ktest],tr_lbl_data[ktest])\n",
    "    print('Test score:', test_score)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    test_cvscores.append(test_acc * 100)\n",
    "print(tr_cvscores)\n",
    "print(test_cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testdata():    \n",
    "#     test_imgs=[]    \n",
    "#     for root,dirs,files in os.walk(test_data): #讀取資料夾影像\n",
    "#         for f in files:\n",
    "#             img=cv2.imread(os.path.join(root,f))\n",
    "#             #print(os.path.join(root,f))\n",
    "#             img=cv2.resize(img,(299,299))\n",
    "#             img=img.reshape(-1, 299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
