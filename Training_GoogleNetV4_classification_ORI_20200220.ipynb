{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras as kr\n",
    "kr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import keras.models\n",
    "import sklearn.model_selection as sk\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Activation, Flatten,add\n",
    "from keras.layers import Input,Dense,Dropout,BatchNormalization,Convolution2D,MaxPooling2D,AveragePooling2D,Concatenate,ZeroPadding2D,GlobalAveragePooling2D\n",
    "from keras.layers import Flatten, Activation, Conv2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model,load_model\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model,np_utils\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.metrics as metric\n",
    "from keras.optimizers import SGD\n",
    "import pydot\n",
    "import os\n",
    "\n",
    "train_data='D:\\\\star\\\\GoogleNetV4_class_ORI_20191015\\\\train\\\\'\n",
    "vaildation_data='D:\\\\star\\\\GoogleNetV4_class_ORI_20191015\\\\vaildation\\\\'\n",
    "\n",
    "#C:\\\\Users\\\\star\\\\GoogleNetV4_sex_20190621\\\\traindata\n",
    "#train_data='D:\\data\\sex\\ctrain\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testdata():    \n",
    "#     test_imgs=[]\n",
    "#     for i in tqdm(os.listdir(test_data)):\n",
    "#         if i[len(i)-1]=='g':\n",
    "#             #print(i)\n",
    "#             test_img=cv2.imread(test_data+i, cv2.IMREAD_COLOR)\n",
    "#             test_imgs=cv2.resize(test_img,(299,299))\n",
    "#     return test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing_images = testdata()\n",
    "# te_img_data = np.array([i for i in testing_images]).reshape(-1,299,299,3)\n",
    "# print(te_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imglabel(nimg):\n",
    "    if (nimg[0]=='A' and nimg[1]=='e') or (nimg[0]=='7' and nimg[1]=='_'):\n",
    "        return np.array([0,0,0,0,0,0,0,1])\n",
    "    elif (nimg[0]=='A' and nimg[1]=='l') or (nimg[0]=='0' and nimg[1]=='_'):\n",
    "        return np.array([0,0,0,0,0,0,1,0])\n",
    "    elif (nimg[0]=='A' and nimg[1]=='r') or (nimg[0]=='1' and nimg[1]=='_'):\n",
    "        return np.array([0,0,0,0,0,1,0,0])\n",
    "    elif (nimg[0] == 'C' and nimg[5] == 't') or (nimg[0]=='4' and nimg[1]=='_'):\n",
    "        return np.array([0,0,0,0,1,0,0,0])\n",
    "    elif (nimg[0]=='C' and nimg[5]=='n') or (nimg[0]=='6' and nimg[1]=='_'):\n",
    "        return np.array([0,0,0,1,0,0,0,0])\n",
    "    elif (nimg[0]=='C' and nimg[5]=='p' and nimg[4]=='x') or (nimg[0]=='5' and nimg[1]=='_'):\n",
    "        return np.array([0,0,1,0,0,0,0,0])\n",
    "    elif (nimg[0]=='C' and nimg[5]=='p' and nimg[4]=='i') or (nimg[0]=='2' and nimg[1]=='_'):\n",
    "        return np.array([0,1,0,0,0,0,0,0])\n",
    "    elif (nimg[0] == 'A' and nimg[1] == 'n') or (nimg[0]=='3' and nimg[1]=='_'):\n",
    "        return np.array([1,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaildationdata():\n",
    "    vaildation_imgs=[]\n",
    "    for i in tqdm(os.listdir(vaildation_data)):\n",
    "        if i[len(i)-1]=='g':\n",
    "            #print(i)\n",
    "            vaoimg=cv2.imread(vaildation_data+i, cv2.IMREAD_COLOR)\n",
    "            #print(i)\n",
    "            #height, width, channels = img.shape\n",
    "            vaimg=cv2.resize(vaoimg,(299,299))\n",
    "            #neimg = cv2.resize(oimg, (224, 224))\n",
    "            #b, g, r = cv2.split(img)\n",
    "            #b = 255 - b\n",
    "            #g = 255 - g\n",
    "            #r = 255 - r\n",
    "            #neimg[:, :, 0] = b\n",
    "            #neimg[:, :, 1] = g\n",
    "            #neimg[:, :, 2] = r\n",
    "            vaildation_imgs.append([np.array(vaimg),imglabel(i)])\n",
    "            #flip_1 = np.fliplr(img)\n",
    "            #flip_2 = np.flipud(img)\n",
    "            #train_imgs.append([np.array(flip_1),imglabel(i)])\n",
    "            #train_imgs.append([np.array(flip_2),imglabel(i)])\n",
    "    return vaildation_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 912/912 [00:05<00:00, 166.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(912, 8)\n"
     ]
    }
   ],
   "source": [
    "vaildation_images = vaildationdata()\n",
    "va_img_data = np.array([i[0] for i in vaildation_images]).reshape(-1,299,299,3)\n",
    "va_lbl_data = np.array([i[1] for i in vaildation_images])\n",
    "print(va_lbl_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindata():\n",
    "    train_imgs=[]\n",
    "    for i in tqdm(os.listdir(train_data)):\n",
    "        if i[len(i)-1]=='g':\n",
    "            #print(i)\n",
    "            oimg=cv2.imread(train_data+i, cv2.IMREAD_COLOR)\n",
    "            #print(i)\n",
    "            #height, width, channels = img.shape\n",
    "            img=cv2.resize(oimg,(299,299))\n",
    "            #neimg = cv2.resize(oimg, (224, 224))\n",
    "            #b, g, r = cv2.split(img)\n",
    "            #b = 255 - b\n",
    "            #g = 255 - g\n",
    "            #r = 255 - r\n",
    "            #neimg[:, :, 0] = b\n",
    "            #neimg[:, :, 1] = g\n",
    "            #neimg[:, :, 2] = r\n",
    "            train_imgs.append([np.array(img),imglabel(i)])\n",
    "            #flip_1 = np.fliplr(img)\n",
    "            #flip_2 = np.flipud(img)\n",
    "            #train_imgs.append([np.array(flip_1),imglabel(i)])\n",
    "            #train_imgs.append([np.array(flip_2),imglabel(i)])\n",
    "    return train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8207/8207 [00:34<00:00, 240.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8207, 8)\n"
     ]
    }
   ],
   "source": [
    "training_images = traindata()\n",
    "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,299,299,3)\n",
    "tr_lbl_data = np.array([i[1] for i in training_images])\n",
    "print(tr_lbl_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立CNN(googlNet)模型，基於inception_4的模塊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_BLOCK_COUNT = 0  # 用来命名计数卷积编号\n",
    "INCEPTION_A_COUNT = 0\n",
    "INCEPTION_B_COUNT = 0\n",
    "INCEPTION_C_COUNT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, nb_filters, nb_row, nb_col, strides=(1, 1), padding='same', use_bias=False):\n",
    "    global CONV_BLOCK_COUNT\n",
    "    CONV_BLOCK_COUNT += 1\n",
    "    with K.name_scope('conv_block_'+str(CONV_BLOCK_COUNT)):\n",
    "        x = Conv2D(filters=nb_filters,\n",
    "                   kernel_size=(nb_row, nb_col),\n",
    "                   strides=strides,\n",
    "                   padding=padding,\n",
    "                   use_bias=use_bias)(x)\n",
    "        x = BatchNormalization(axis=-1, momentum=0.9, scale=False)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(x_input):\n",
    "    with K.name_scope('stem'):\n",
    "        x = conv_block(x_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "        x = conv_block(x, 32, 3, 3, padding='valid')\n",
    "        x = conv_block(x, 64, 3, 3)\n",
    " \n",
    "        x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "        x2 = conv_block(x, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        x = concatenate([x1, x2], axis=-1)\n",
    " \n",
    "        x1 = conv_block(x, 64, 1, 1)\n",
    "        x1 = conv_block(x1, 96, 3, 3, padding='valid')\n",
    " \n",
    "        x2 = conv_block(x, 64, 1, 1)\n",
    "        x2 = conv_block(x2, 64, 7, 1)\n",
    "        x2 = conv_block(x2, 64, 1, 7)\n",
    "        x2 = conv_block(x2, 96, 3, 3, padding='valid')\n",
    " \n",
    "        x = concatenate([x1, x2], axis=-1)\n",
    " \n",
    "        x1 = conv_block(x, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "        x2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    " \n",
    "        merged_vector = concatenate([x1, x2], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_A(x_input):\n",
    "    \"\"\"35*35 卷积块\"\"\"\n",
    "    global INCEPTION_A_COUNT\n",
    "    INCEPTION_A_COUNT += 1\n",
    "    with K.name_scope('inception_A' + str(INCEPTION_A_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)  # 35 * 35 * 192\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 96, 1, 1)  # 35 * 35 * 96\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 96, 1, 1)  # 35 * 35 * 96\n",
    " \n",
    "        conv1x1_3x3 = conv_block(x_input, 64, 1, 1)  # 35 * 35 * 64\n",
    "        conv1x1_3x3 = conv_block(conv1x1_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    " \n",
    "        conv3x3_3x3 = conv_block(x_input, 64, 1, 1)  # 35 * 35 * 64\n",
    "        conv3x3_3x3 = conv_block(conv3x3_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    "        conv3x3_3x3 = conv_block(conv3x3_3x3, 96, 3, 3)  # 35 * 35 * 96\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv1x1_3x3, conv3x3_3x3], axis=-1)  # 35 * 35 * 384\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_B(x_input):\n",
    "    \"\"\"17*17 卷积块\"\"\"\n",
    "    global INCEPTION_B_COUNT\n",
    "    INCEPTION_B_COUNT += 1\n",
    "    with K.name_scope('inception_B' + str(INCEPTION_B_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 128, 1, 1)\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 384, 1, 1)\n",
    " \n",
    "        conv1x7_1x7 = conv_block(x_input, 192, 1, 1)\n",
    "        conv1x7_1x7 = conv_block(conv1x7_1x7, 224, 1, 7)\n",
    "        conv1x7_1x7 = conv_block(conv1x7_1x7, 256, 1, 7)\n",
    " \n",
    "        conv2_1x7_7x1 = conv_block(x_input, 192, 1, 1)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 192, 1, 7)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 224, 7, 1)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 224, 1, 7)\n",
    "        conv2_1x7_7x1 = conv_block(conv2_1x7_7x1, 256, 7, 1)\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv1x7_1x7, conv2_1x7_7x1], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_C(x_input):\n",
    "    \"\"\"8*8 卷积块\"\"\"\n",
    "    global INCEPTION_C_COUNT\n",
    "    INCEPTION_C_COUNT += 1\n",
    "    with K.name_scope('Inception_C' + str(INCEPTION_C_COUNT)):\n",
    "        averagepooling_conv1x1 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x_input)\n",
    "        averagepooling_conv1x1 = conv_block(averagepooling_conv1x1, 256, 1, 1)\n",
    " \n",
    "        conv1x1 = conv_block(x_input, 256, 1, 1)\n",
    " \n",
    "        # 用 1x3 和 3x1 替代 3x3\n",
    "        conv3x3_1x1 = conv_block(x_input, 384, 1, 1)\n",
    "        conv3x3_1 = conv_block(conv3x3_1x1, 256, 1, 3)\n",
    "        conv3x3_2 = conv_block(conv3x3_1x1, 256, 3, 1)\n",
    " \n",
    "        conv2_3x3_1x1 = conv_block(x_input, 384, 1, 1)\n",
    "        conv2_3x3_1x1 = conv_block(conv2_3x3_1x1, 448, 1, 3)\n",
    "        conv2_3x3_1x1 = conv_block(conv2_3x3_1x1, 512, 3, 1)\n",
    "        conv2_3x3_1x1_1 = conv_block(conv2_3x3_1x1, 256, 3, 1)\n",
    "        conv2_3x3_1x1_2 = conv_block(conv2_3x3_1x1, 256, 1, 3)\n",
    " \n",
    "        merged_vector = concatenate([averagepooling_conv1x1, conv1x1, conv3x3_1, conv3x3_2, conv2_3x3_1x1_1, conv2_3x3_1x1_2], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_A(x_input, k=192, l=224, m=256, n=384):\n",
    "    with K.name_scope('Reduction_A'):\n",
    "        \"\"\"Architecture of a 35 * 35 to 17 * 17 Reduction_A block.\"\"\"\n",
    "        maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x_input)\n",
    " \n",
    "        conv3x3 = conv_block(x_input, n, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        conv2_3x3 = conv_block(x_input, k, 1, 1)\n",
    "        conv2_3x3 = conv_block(conv2_3x3, l, 3, 3)\n",
    "        conv2_3x3 = conv_block(conv2_3x3, m, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        merged_vector = concatenate([maxpool, conv3x3, conv2_3x3], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_B(x_input):\n",
    "    \"\"\"Architecture of a 17 * 17 to 8 * 8 Reduction_B block.\"\"\"\n",
    "    with K.name_scope('Reduction_B'):\n",
    "        maxpool = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x_input)\n",
    " \n",
    "        conv3x3 = conv_block(x_input, 192, 1, 1)\n",
    "        conv3x3 = conv_block(conv3x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        conv1x7_7x1_3x3 = conv_block(x_input, 256, 1, 1)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 256, 1, 7)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 320, 7, 1)\n",
    "        conv1x7_7x1_3x3 = conv_block(conv1x7_7x1_3x3, 320, 3, 3, strides=(2, 2), padding='valid')\n",
    " \n",
    "        merged_vector = concatenate([maxpool, conv3x3, conv1x7_7x1_3x3], axis=-1)\n",
    "    return merged_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v4_backbone(nb_classes=8, load_weights=True):\n",
    "    x_input = Input(shape=(299, 299, 3))\n",
    "    # Stem\n",
    "    x = stem(x_input)  # 35 x 35 x 384\n",
    "    # 4 x Inception_A\n",
    "    for i in range(4):\n",
    "        x = inception_A(x)  # 35 x 35 x 384\n",
    "    # Reduction_A\n",
    "    x = reduction_A(x, k=192, l=224, m=256, n=384)  # 17 x 17 x 1024\n",
    "    # 7 x Inception_B\n",
    "    for i in range(7):\n",
    "        x = inception_B(x)  # 17 x 17 x1024\n",
    "    # Reduction_B\n",
    "    x = reduction_B(x)  # 8 x 8 x 1536\n",
    "    # Average Pooling\n",
    "    x = AveragePooling2D(pool_size=(8, 8))(x)  # 1536\n",
    "    # dropout\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)  # 1536\n",
    "    # 全连接层\n",
    "    x = Dense(units=nb_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=x_input, outputs=x, name='Inception-V4')\n",
    "    model.save('googlenetV4_classification_ORI_20200224_epoch250_shuffle.h5')    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將model存下來(per Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model_path ='D:\\\\star\\\\GoogleNetV4_class_ORI_20191015\\\\model_20200224_epoch250\\\\'\n",
    "\n",
    "model_name = \"checkpoint-{epoch:02d}e-val_acc_{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.path.join(model_path,model_name),\n",
    "                             monitor='val_acc',verbose=1,save_best_only=False, save_weights_only=False,\n",
    "                             mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 96)   55296       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 96)   288         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 96)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 73, 73, 160)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 73, 73, 64)   10240       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 73, 73, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 73, 73, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 73, 73, 64)   28672       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 73, 73, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 73, 73, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 73, 73, 64)   10240       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 73, 73, 64)   28672       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 73, 73, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 73, 73, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 73, 73, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 73, 73, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 71, 71, 96)   55296       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 71, 71, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 71, 71, 96)   288         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 71, 71, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 71, 71, 96)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 71, 71, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 71, 71, 192)  0           activation_6[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 192)  331776      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 192)  576         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 192)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 35, 35, 384)  0           activation_11[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 384)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 96)   55296       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 96)   288         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 96)   288         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 96)   288         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 96)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 96)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 35, 35, 384)  0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 384)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 96)   55296       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 96)   288         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 96)   288         conv2d_20[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 96)   288         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 96)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 96)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 96)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 35, 35, 384)  0           activation_19[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 96)   55296       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 96)   288         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 384)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 96)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 96)   82944       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 96)   288         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 96)   288         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 96)   288         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 96)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 96)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 96)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 35, 35, 384)  0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 64)   192         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 64)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 64)   24576       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 96)   55296       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 96)   288         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 35, 35, 384)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 96)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 96)   36864       average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 96)   36864       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 96)   55296       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 96)   82944       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 96)   288         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 96)   288         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 96)   288         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 96)   288         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 96)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 96)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 96)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 96)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 35, 35, 384)  0           activation_33[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 192)  73728       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 224)  387072      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 224)  672         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 224)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 384)  1327104     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 256)  516096      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 384)  1152        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 256)  768         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 384)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 384)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 256)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 17, 17, 1024) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  258048      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 224)  301056      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 192)  576         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_51 (BatchNo (None, 17, 17, 224)  672         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 192)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 224)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 224)  301056      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 224)  351232      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 224)  672         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 224)  672         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 1024) 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 224)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 224)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 256)  401408      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 256)  401408      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 128)  384         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 384)  1152        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 256)  768         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 256)  768         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 384)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 256)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 256)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 17, 17, 1024) 0           activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  258048      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 224)  301056      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 192)  576         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 224)  672         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 192)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 224)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 224)  301056      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 224)  351232      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 224)  672         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 224)  672         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 1024) 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 224)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 224)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 256)  401408      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 256)  401408      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 128)  384         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 384)  1152        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 256)  768         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 256)  768         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 128)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 384)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 256)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 256)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 17, 17, 1024) 0           activation_54[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  258048      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 224)  301056      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 224)  672         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 224)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 224)  301056      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 224)  351232      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 224)  672         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 224)  672         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 1024) 0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 224)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 224)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 256)  401408      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 256)  401408      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 128)  384         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_65 (BatchNo (None, 17, 17, 384)  1152        conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 256)  768         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 128)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 384)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 256)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 17, 17, 1024) 0           activation_64[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 192)  258048      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 224)  301056      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 224)  672         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 224)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 224)  301056      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 224)  351232      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 224)  672         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 224)  672         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 17, 17, 1024) 0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 224)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 224)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 256)  401408      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 256)  401408      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 128)  384         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 256)  768         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 256)  768         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 17, 17, 1024) 0           activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 activation_78[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 192)  258048      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 192)  576         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 192)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 224)  301056      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 192)  576         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 224)  672         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 192)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 224)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 224)  301056      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 224)  351232      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 224)  672         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 224)  672         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 17, 17, 1024) 0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 224)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 224)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 256)  401408      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 256)  401408      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 128)  384         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 384)  1152        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 256)  768         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 256)  768         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 128)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 384)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 17, 17, 1024) 0           activation_84[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 17, 17, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 17, 17, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 192)  258048      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 192)  196608      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 17, 17, 224)  301056      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 17, 17, 224)  672         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 17, 17, 224)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 224)  301056      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 17, 17, 224)  351232      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 17, 17, 224)  672         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 17, 17, 224)  672         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 17, 17, 1024) 0           concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 17, 17, 224)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 17, 17, 224)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 128)  131072      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 384)  393216      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 256)  401408      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 17, 17, 256)  401408      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 128)  384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 384)  1152        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 17, 17, 256)  768         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 17, 17, 256)  768         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 128)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 17, 17, 384)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 17, 17, 256)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 17, 17, 256)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 17, 17, 1024) 0           activation_94[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "                                                                 activation_98[0][0]              \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 17, 17, 192)  576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 17, 17, 192)  258048      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 17, 17, 192)  576         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 17, 17, 192)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 17, 17, 224)  301056      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 17, 17, 192)  576         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 17, 17, 224)  672         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 17, 17, 192)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 17, 17, 224)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 17, 17, 224)  301056      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 17, 17, 224)  351232      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 17, 17, 224)  672         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 17, 17, 224)  672         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 17, 17, 1024) 0           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 17, 17, 224)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 17, 17, 224)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 17, 17, 128)  131072      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 17, 17, 384)  393216      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 17, 17, 256)  401408      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 17, 17, 256)  401408      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 17, 17, 128)  384         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 17, 17, 384)  1152        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 17, 17, 256)  768         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 17, 17, 256)  768         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 17, 17, 128)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 17, 17, 384)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 17, 17, 256)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 17, 17, 256)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 17, 17, 1024) 0           activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 17, 17, 256)  262144      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 17, 17, 256)  768         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 17, 17, 256)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 17, 17, 256)  458752      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 17, 17, 256)  768         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 17, 17, 256)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 17, 17, 192)  196608      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 17, 17, 320)  573440      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 17, 17, 192)  576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 17, 17, 320)  960         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 17, 17, 192)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 17, 17, 320)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 192)    331776      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 8, 8, 320)    921600      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 192)    576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 320)    960         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 8, 8, 192)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 8, 8, 320)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 1536)   0           max_pooling2d_4[0][0]            \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_119[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 1, 1, 1536)   0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 1, 1536)   0           average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1536)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            12296       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,517,640\n",
      "Trainable params: 27,474,056\n",
      "Non-trainable params: 43,584\n",
      "__________________________________________________________________________________________________\n",
      "Train on 8207 samples, validate on 912 samples\n",
      "Epoch 1/250\n",
      " - 150s - loss: 2.0116 - acc: 0.3552 - val_loss: 7.0350 - val_acc: 0.2336\n",
      "Epoch 2/250\n",
      " - 137s - loss: 1.7567 - acc: 0.4644 - val_loss: 1.6057 - val_acc: 0.4156\n",
      "Epoch 3/250\n",
      " - 138s - loss: 1.4809 - acc: 0.5354 - val_loss: 1.3373 - val_acc: 0.5263\n",
      "Epoch 4/250\n",
      " - 141s - loss: 1.2376 - acc: 0.6059 - val_loss: 1.4169 - val_acc: 0.5581\n",
      "Epoch 5/250\n",
      " - 141s - loss: 0.7843 - acc: 0.7243 - val_loss: 0.7054 - val_acc: 0.7500\n",
      "Epoch 6/250\n",
      " - 140s - loss: 0.6121 - acc: 0.7860 - val_loss: 1.3226 - val_acc: 0.5735\n",
      "Epoch 7/250\n",
      " - 143s - loss: 0.5215 - acc: 0.8200 - val_loss: 1.3445 - val_acc: 0.5866\n",
      "Epoch 8/250\n",
      " - 138s - loss: 0.4282 - acc: 0.8462 - val_loss: 0.6482 - val_acc: 0.7873\n",
      "Epoch 9/250\n",
      " - 139s - loss: 0.3494 - acc: 0.8789 - val_loss: 0.9510 - val_acc: 0.8026\n",
      "Epoch 10/250\n",
      " - 141s - loss: 0.3518 - acc: 0.8790 - val_loss: 0.5545 - val_acc: 0.8147\n",
      "Epoch 11/250\n",
      " - 140s - loss: 0.3025 - acc: 0.8937 - val_loss: 0.3613 - val_acc: 0.8827\n",
      "Epoch 12/250\n",
      " - 138s - loss: 0.2460 - acc: 0.9136 - val_loss: 0.3483 - val_acc: 0.8794\n",
      "Epoch 13/250\n",
      " - 137s - loss: 0.2482 - acc: 0.9143 - val_loss: 0.3364 - val_acc: 0.8914\n",
      "Epoch 14/250\n",
      " - 136s - loss: 0.2154 - acc: 0.9221 - val_loss: 0.5178 - val_acc: 0.8322\n",
      "Epoch 15/250\n",
      " - 136s - loss: 0.1977 - acc: 0.9277 - val_loss: 0.3759 - val_acc: 0.8684\n",
      "Epoch 16/250\n",
      " - 136s - loss: 0.1786 - acc: 0.9377 - val_loss: 0.2540 - val_acc: 0.9178\n",
      "Epoch 17/250\n",
      " - 136s - loss: 0.1803 - acc: 0.9372 - val_loss: 0.4883 - val_acc: 0.8443\n",
      "Epoch 18/250\n",
      " - 138s - loss: 0.1430 - acc: 0.9521 - val_loss: 0.5451 - val_acc: 0.8443\n",
      "Epoch 19/250\n",
      " - 141s - loss: 0.1578 - acc: 0.9436 - val_loss: 0.7477 - val_acc: 0.7971\n",
      "Epoch 20/250\n",
      " - 139s - loss: 0.1372 - acc: 0.9526 - val_loss: 0.3376 - val_acc: 0.9035\n",
      "Epoch 21/250\n",
      " - 139s - loss: 0.1270 - acc: 0.9571 - val_loss: 0.2682 - val_acc: 0.9200\n",
      "Epoch 22/250\n",
      " - 138s - loss: 0.1228 - acc: 0.9587 - val_loss: 1.0968 - val_acc: 0.7522\n",
      "Epoch 23/250\n",
      " - 136s - loss: 0.0921 - acc: 0.9693 - val_loss: 0.2136 - val_acc: 0.9353\n",
      "Epoch 24/250\n",
      " - 137s - loss: 0.0916 - acc: 0.9704 - val_loss: 0.3904 - val_acc: 0.8761\n",
      "Epoch 25/250\n",
      " - 138s - loss: 0.1027 - acc: 0.9673 - val_loss: 0.2472 - val_acc: 0.9298\n",
      "Epoch 26/250\n",
      " - 138s - loss: 0.0736 - acc: 0.9765 - val_loss: 0.2862 - val_acc: 0.9254\n",
      "Epoch 27/250\n",
      " - 137s - loss: 0.0903 - acc: 0.9699 - val_loss: 0.2013 - val_acc: 0.9463\n",
      "Epoch 28/250\n",
      " - 136s - loss: 0.0607 - acc: 0.9810 - val_loss: 0.2906 - val_acc: 0.9134\n",
      "Epoch 29/250\n",
      " - 137s - loss: 0.0575 - acc: 0.9789 - val_loss: 0.2925 - val_acc: 0.9287\n",
      "Epoch 30/250\n",
      " - 137s - loss: 0.0596 - acc: 0.9804 - val_loss: 0.2282 - val_acc: 0.9474\n",
      "Epoch 31/250\n",
      " - 137s - loss: 0.0697 - acc: 0.9750 - val_loss: 0.3134 - val_acc: 0.9211\n",
      "Epoch 32/250\n",
      " - 137s - loss: 0.0575 - acc: 0.9806 - val_loss: 0.2125 - val_acc: 0.9309\n",
      "Epoch 33/250\n",
      " - 137s - loss: 0.0545 - acc: 0.9816 - val_loss: 0.2380 - val_acc: 0.9353\n",
      "Epoch 34/250\n",
      " - 137s - loss: 0.0405 - acc: 0.9871 - val_loss: 0.1857 - val_acc: 0.9452\n",
      "Epoch 35/250\n",
      " - 139s - loss: 0.0432 - acc: 0.9856 - val_loss: 0.6162 - val_acc: 0.8377\n",
      "Epoch 36/250\n",
      " - 136s - loss: 0.0677 - acc: 0.9781 - val_loss: 1.2729 - val_acc: 0.7489\n",
      "Epoch 37/250\n",
      " - 136s - loss: 0.0544 - acc: 0.9806 - val_loss: 0.1869 - val_acc: 0.9452\n",
      "Epoch 38/250\n",
      " - 136s - loss: 0.0273 - acc: 0.9910 - val_loss: 0.2307 - val_acc: 0.9342\n",
      "Epoch 39/250\n",
      " - 136s - loss: 0.0566 - acc: 0.9807 - val_loss: 0.3771 - val_acc: 0.8882\n",
      "Epoch 40/250\n",
      " - 136s - loss: 0.0375 - acc: 0.9864 - val_loss: 0.8796 - val_acc: 0.8377\n",
      "Epoch 41/250\n",
      " - 136s - loss: 0.0284 - acc: 0.9906 - val_loss: 0.2640 - val_acc: 0.9353\n",
      "Epoch 42/250\n",
      " - 136s - loss: 0.0564 - acc: 0.9822 - val_loss: 0.5762 - val_acc: 0.8629\n",
      "Epoch 43/250\n",
      " - 136s - loss: 0.0361 - acc: 0.9878 - val_loss: 0.2511 - val_acc: 0.9254\n",
      "Epoch 44/250\n",
      " - 136s - loss: 0.0263 - acc: 0.9928 - val_loss: 0.5752 - val_acc: 0.8695\n",
      "Epoch 45/250\n",
      " - 136s - loss: 0.0300 - acc: 0.9912 - val_loss: 0.2431 - val_acc: 0.9397\n",
      "Epoch 46/250\n",
      " - 136s - loss: 0.0185 - acc: 0.9948 - val_loss: 0.2611 - val_acc: 0.9342\n",
      "Epoch 47/250\n",
      " - 136s - loss: 0.0301 - acc: 0.9911 - val_loss: 0.1993 - val_acc: 0.9518\n",
      "Epoch 48/250\n",
      " - 136s - loss: 0.0456 - acc: 0.9855 - val_loss: 0.4197 - val_acc: 0.8783\n",
      "Epoch 49/250\n",
      " - 136s - loss: 0.0428 - acc: 0.9857 - val_loss: 0.2279 - val_acc: 0.9408\n",
      "Epoch 50/250\n",
      " - 136s - loss: 0.0144 - acc: 0.9956 - val_loss: 0.1427 - val_acc: 0.9649\n",
      "Epoch 51/250\n",
      " - 136s - loss: 0.0245 - acc: 0.9923 - val_loss: 0.2194 - val_acc: 0.9452\n",
      "Epoch 52/250\n",
      " - 136s - loss: 0.0129 - acc: 0.9962 - val_loss: 0.2035 - val_acc: 0.9529\n",
      "Epoch 53/250\n",
      " - 136s - loss: 0.0231 - acc: 0.9920 - val_loss: 0.1876 - val_acc: 0.9485\n",
      "Epoch 54/250\n",
      " - 136s - loss: 0.0203 - acc: 0.9931 - val_loss: 0.2372 - val_acc: 0.9485\n",
      "Epoch 55/250\n",
      " - 136s - loss: 0.0176 - acc: 0.9937 - val_loss: 0.1503 - val_acc: 0.9627\n",
      "Epoch 56/250\n",
      " - 136s - loss: 0.0122 - acc: 0.9967 - val_loss: 0.2279 - val_acc: 0.9572\n",
      "Epoch 57/250\n",
      " - 136s - loss: 0.0207 - acc: 0.9945 - val_loss: 0.2271 - val_acc: 0.9627\n",
      "Epoch 58/250\n",
      " - 136s - loss: 0.0147 - acc: 0.9956 - val_loss: 0.2618 - val_acc: 0.9419\n",
      "Epoch 59/250\n",
      " - 137s - loss: 0.0163 - acc: 0.9951 - val_loss: 0.1857 - val_acc: 0.9518\n",
      "Epoch 60/250\n",
      " - 141s - loss: 0.0144 - acc: 0.9954 - val_loss: 0.8269 - val_acc: 0.7906\n",
      "Epoch 61/250\n",
      " - 143s - loss: 0.0253 - acc: 0.9917 - val_loss: 0.1754 - val_acc: 0.9594\n",
      "Epoch 62/250\n",
      " - 142s - loss: 0.0172 - acc: 0.9954 - val_loss: 0.1760 - val_acc: 0.9529\n",
      "Epoch 63/250\n",
      " - 142s - loss: 0.0337 - acc: 0.9899 - val_loss: 0.1228 - val_acc: 0.9671\n",
      "Epoch 64/250\n",
      " - 143s - loss: 0.0117 - acc: 0.9962 - val_loss: 0.1518 - val_acc: 0.9649\n",
      "Epoch 65/250\n",
      " - 141s - loss: 0.0128 - acc: 0.9959 - val_loss: 0.1801 - val_acc: 0.9518\n",
      "Epoch 66/250\n",
      " - 141s - loss: 0.0130 - acc: 0.9955 - val_loss: 0.1511 - val_acc: 0.9693\n",
      "Epoch 67/250\n",
      " - 141s - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1834 - val_acc: 0.9529\n",
      "Epoch 68/250\n",
      " - 140s - loss: 0.0236 - acc: 0.9931 - val_loss: 0.1783 - val_acc: 0.9627\n",
      "Epoch 69/250\n",
      " - 139s - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1773 - val_acc: 0.9704\n",
      "Epoch 70/250\n",
      " - 144s - loss: 0.0153 - acc: 0.9949 - val_loss: 0.2395 - val_acc: 0.9496\n",
      "Epoch 71/250\n",
      " - 142s - loss: 0.0182 - acc: 0.9933 - val_loss: 0.2091 - val_acc: 0.9561\n",
      "Epoch 72/250\n",
      " - 141s - loss: 0.0062 - acc: 0.9979 - val_loss: 0.1593 - val_acc: 0.9627\n",
      "Epoch 73/250\n",
      " - 145s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.1628 - val_acc: 0.9616\n",
      "Epoch 74/250\n",
      " - 145s - loss: 0.0143 - acc: 0.9949 - val_loss: 0.1942 - val_acc: 0.9605\n",
      "Epoch 75/250\n",
      " - 143s - loss: 0.0233 - acc: 0.9921 - val_loss: 0.2111 - val_acc: 0.9496\n",
      "Epoch 76/250\n",
      " - 142s - loss: 0.0244 - acc: 0.9918 - val_loss: 0.1932 - val_acc: 0.9539\n",
      "Epoch 77/250\n",
      " - 142s - loss: 0.0212 - acc: 0.9923 - val_loss: 0.2101 - val_acc: 0.9539\n",
      "Epoch 78/250\n",
      " - 139s - loss: 0.0153 - acc: 0.9951 - val_loss: 0.1833 - val_acc: 0.9561\n",
      "Epoch 79/250\n",
      " - 136s - loss: 0.0127 - acc: 0.9968 - val_loss: 0.1539 - val_acc: 0.9671\n",
      "Epoch 80/250\n",
      " - 136s - loss: 0.0059 - acc: 0.9983 - val_loss: 0.1273 - val_acc: 0.9682\n",
      "Epoch 81/250\n",
      " - 137s - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1812 - val_acc: 0.9572\n",
      "Epoch 82/250\n",
      " - 136s - loss: 0.0060 - acc: 0.9984 - val_loss: 0.1564 - val_acc: 0.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/250\n",
      " - 138s - loss: 0.0100 - acc: 0.9966 - val_loss: 0.1757 - val_acc: 0.9660\n",
      "Epoch 84/250\n",
      " - 138s - loss: 0.0228 - acc: 0.9932 - val_loss: 0.2124 - val_acc: 0.9529\n",
      "Epoch 85/250\n",
      " - 136s - loss: 0.0080 - acc: 0.9971 - val_loss: 0.1624 - val_acc: 0.9616\n",
      "Epoch 86/250\n",
      " - 136s - loss: 0.0095 - acc: 0.9976 - val_loss: 0.1883 - val_acc: 0.9594\n",
      "Epoch 87/250\n",
      " - 136s - loss: 0.0076 - acc: 0.9976 - val_loss: 0.1416 - val_acc: 0.9671\n",
      "Epoch 88/250\n",
      " - 136s - loss: 0.0105 - acc: 0.9962 - val_loss: 0.1516 - val_acc: 0.9649\n",
      "Epoch 89/250\n",
      " - 136s - loss: 0.0150 - acc: 0.9957 - val_loss: 0.1764 - val_acc: 0.9682\n",
      "Epoch 90/250\n",
      " - 136s - loss: 0.0203 - acc: 0.9933 - val_loss: 0.2158 - val_acc: 0.9518\n",
      "Epoch 91/250\n",
      " - 137s - loss: 0.0236 - acc: 0.9916 - val_loss: 0.1569 - val_acc: 0.9561\n",
      "Epoch 92/250\n",
      " - 137s - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1603 - val_acc: 0.9616\n",
      "Epoch 93/250\n",
      " - 136s - loss: 0.0118 - acc: 0.9970 - val_loss: 0.2884 - val_acc: 0.9298\n",
      "Epoch 94/250\n",
      " - 137s - loss: 0.0126 - acc: 0.9963 - val_loss: 0.1651 - val_acc: 0.9561\n",
      "Epoch 95/250\n",
      " - 136s - loss: 0.0066 - acc: 0.9984 - val_loss: 0.1409 - val_acc: 0.9627\n",
      "Epoch 96/250\n",
      " - 136s - loss: 0.0066 - acc: 0.9979 - val_loss: 0.1360 - val_acc: 0.9682\n",
      "Epoch 97/250\n",
      " - 136s - loss: 0.0061 - acc: 0.9982 - val_loss: 0.1499 - val_acc: 0.9605\n",
      "Epoch 98/250\n",
      " - 136s - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1764 - val_acc: 0.9561\n",
      "Epoch 99/250\n",
      " - 136s - loss: 0.0064 - acc: 0.9978 - val_loss: 0.1469 - val_acc: 0.9605\n",
      "Epoch 100/250\n",
      " - 136s - loss: 0.0062 - acc: 0.9979 - val_loss: 0.1755 - val_acc: 0.9660\n",
      "Epoch 101/250\n",
      " - 136s - loss: 0.0213 - acc: 0.9937 - val_loss: 0.1712 - val_acc: 0.9561\n",
      "Epoch 102/250\n",
      " - 136s - loss: 0.0107 - acc: 0.9965 - val_loss: 0.1572 - val_acc: 0.9649\n",
      "Epoch 103/250\n",
      " - 136s - loss: 0.0072 - acc: 0.9973 - val_loss: 0.1640 - val_acc: 0.9660\n",
      "Epoch 104/250\n",
      " - 136s - loss: 0.0084 - acc: 0.9970 - val_loss: 0.1287 - val_acc: 0.9682\n",
      "Epoch 105/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1324 - val_acc: 0.9638\n",
      "Epoch 106/250\n",
      " - 136s - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2301 - val_acc: 0.9474\n",
      "Epoch 107/250\n",
      " - 136s - loss: 0.0070 - acc: 0.9976 - val_loss: 0.2121 - val_acc: 0.9529\n",
      "Epoch 108/250\n",
      " - 136s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1478 - val_acc: 0.9594\n",
      "Epoch 109/250\n",
      " - 136s - loss: 0.0037 - acc: 0.9987 - val_loss: 0.1271 - val_acc: 0.9715\n",
      "Epoch 110/250\n",
      " - 137s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1445 - val_acc: 0.9627\n",
      "Epoch 111/250\n",
      " - 136s - loss: 0.0033 - acc: 0.9994 - val_loss: 0.1496 - val_acc: 0.9638\n",
      "Epoch 112/250\n",
      " - 136s - loss: 9.9223e-04 - acc: 0.9999 - val_loss: 0.1622 - val_acc: 0.9693\n",
      "Epoch 113/250\n",
      " - 137s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.1565 - val_acc: 0.9671\n",
      "Epoch 114/250\n",
      " - 137s - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1342 - val_acc: 0.9638\n",
      "Epoch 115/250\n",
      " - 139s - loss: 0.0091 - acc: 0.9971 - val_loss: 0.1872 - val_acc: 0.9627\n",
      "Epoch 116/250\n",
      " - 140s - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1614 - val_acc: 0.9748\n",
      "Epoch 117/250\n",
      " - 136s - loss: 8.0628e-04 - acc: 0.9999 - val_loss: 0.1406 - val_acc: 0.9693\n",
      "Epoch 118/250\n",
      " - 136s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.1347 - val_acc: 0.9671\n",
      "Epoch 119/250\n",
      " - 136s - loss: 0.0046 - acc: 0.9987 - val_loss: 0.1480 - val_acc: 0.9616\n",
      "Epoch 120/250\n",
      " - 136s - loss: 0.0085 - acc: 0.9973 - val_loss: 0.1449 - val_acc: 0.9660\n",
      "Epoch 121/250\n",
      " - 137s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.1335 - val_acc: 0.9682\n",
      "Epoch 122/250\n",
      " - 137s - loss: 0.0148 - acc: 0.9942 - val_loss: 0.1579 - val_acc: 0.9594\n",
      "Epoch 123/250\n",
      " - 136s - loss: 0.0048 - acc: 0.9984 - val_loss: 0.1625 - val_acc: 0.9671\n",
      "Epoch 124/250\n",
      " - 136s - loss: 0.0099 - acc: 0.9968 - val_loss: 0.2002 - val_acc: 0.9561\n",
      "Epoch 125/250\n",
      " - 136s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.1330 - val_acc: 0.9660\n",
      "Epoch 126/250\n",
      " - 137s - loss: 0.0045 - acc: 0.9985 - val_loss: 0.1407 - val_acc: 0.9638\n",
      "Epoch 127/250\n",
      " - 137s - loss: 6.7316e-04 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 0.9715\n",
      "Epoch 128/250\n",
      " - 137s - loss: 4.7777e-04 - acc: 1.0000 - val_loss: 0.1284 - val_acc: 0.9693\n",
      "Epoch 129/250\n",
      " - 136s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.1506 - val_acc: 0.9671\n",
      "Epoch 130/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1552 - val_acc: 0.9671\n",
      "Epoch 131/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9996 - val_loss: 0.2347 - val_acc: 0.9485\n",
      "Epoch 132/250\n",
      " - 136s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.1598 - val_acc: 0.9671\n",
      "Epoch 133/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1428 - val_acc: 0.9682\n",
      "Epoch 134/250\n",
      " - 136s - loss: 0.0023 - acc: 0.9993 - val_loss: 0.1696 - val_acc: 0.9616\n",
      "Epoch 135/250\n",
      " - 138s - loss: 0.0031 - acc: 0.9995 - val_loss: 0.1465 - val_acc: 0.9693\n",
      "Epoch 136/250\n",
      " - 136s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.1622 - val_acc: 0.9638\n",
      "Epoch 137/250\n",
      " - 136s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1401 - val_acc: 0.9682\n",
      "Epoch 138/250\n",
      " - 136s - loss: 0.0092 - acc: 0.9972 - val_loss: 0.1688 - val_acc: 0.9605\n",
      "Epoch 139/250\n",
      " - 136s - loss: 0.0078 - acc: 0.9974 - val_loss: 0.1784 - val_acc: 0.9660\n",
      "Epoch 140/250\n",
      " - 136s - loss: 0.0027 - acc: 0.9991 - val_loss: 0.1665 - val_acc: 0.9671\n",
      "Epoch 141/250\n",
      " - 136s - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1863 - val_acc: 0.9671\n",
      "Epoch 142/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1870 - val_acc: 0.9660\n",
      "Epoch 143/250\n",
      " - 136s - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1716 - val_acc: 0.9638\n",
      "Epoch 144/250\n",
      " - 136s - loss: 0.0060 - acc: 0.9974 - val_loss: 0.1884 - val_acc: 0.9616\n",
      "Epoch 145/250\n",
      " - 137s - loss: 0.0181 - acc: 0.9945 - val_loss: 0.1921 - val_acc: 0.9496\n",
      "Epoch 146/250\n",
      " - 140s - loss: 0.0222 - acc: 0.9942 - val_loss: 0.1711 - val_acc: 0.9605\n",
      "Epoch 147/250\n",
      " - 139s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.1598 - val_acc: 0.9638\n",
      "Epoch 148/250\n",
      " - 136s - loss: 0.0083 - acc: 0.9968 - val_loss: 0.1574 - val_acc: 0.9671\n",
      "Epoch 149/250\n",
      " - 136s - loss: 0.0121 - acc: 0.9957 - val_loss: 0.1780 - val_acc: 0.9594\n",
      "Epoch 150/250\n",
      " - 136s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1786 - val_acc: 0.9572\n",
      "Epoch 151/250\n",
      " - 136s - loss: 0.0048 - acc: 0.9981 - val_loss: 0.1578 - val_acc: 0.9693\n",
      "Epoch 152/250\n",
      " - 136s - loss: 0.0035 - acc: 0.9987 - val_loss: 0.1408 - val_acc: 0.9715\n",
      "Epoch 153/250\n",
      " - 136s - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1660 - val_acc: 0.9660\n",
      "Epoch 154/250\n",
      " - 136s - loss: 0.0039 - acc: 0.9990 - val_loss: 0.1593 - val_acc: 0.9682\n",
      "Epoch 155/250\n",
      " - 136s - loss: 0.0028 - acc: 0.9989 - val_loss: 0.1886 - val_acc: 0.9616\n",
      "Epoch 156/250\n",
      " - 136s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.1705 - val_acc: 0.9671\n",
      "Epoch 157/250\n",
      " - 136s - loss: 7.8170e-04 - acc: 1.0000 - val_loss: 0.1514 - val_acc: 0.9704\n",
      "Epoch 158/250\n",
      " - 136s - loss: 4.7888e-04 - acc: 1.0000 - val_loss: 0.1839 - val_acc: 0.9671\n",
      "Epoch 159/250\n",
      " - 136s - loss: 4.2452e-04 - acc: 0.9999 - val_loss: 0.1678 - val_acc: 0.9682\n",
      "Epoch 160/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.1654 - val_acc: 0.9682\n",
      "Epoch 161/250\n",
      " - 136s - loss: 0.0023 - acc: 0.9994 - val_loss: 0.1705 - val_acc: 0.9682\n",
      "Epoch 162/250\n",
      " - 136s - loss: 6.0677e-04 - acc: 0.9999 - val_loss: 0.1584 - val_acc: 0.9693\n",
      "Epoch 163/250\n",
      " - 136s - loss: 0.0030 - acc: 0.9991 - val_loss: 0.1389 - val_acc: 0.9726\n",
      "Epoch 164/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1586 - val_acc: 0.9660\n",
      "Epoch 165/250\n",
      " - 136s - loss: 7.7707e-04 - acc: 0.9996 - val_loss: 0.1641 - val_acc: 0.9693\n",
      "Epoch 166/250\n",
      " - 136s - loss: 8.4392e-04 - acc: 0.9998 - val_loss: 0.1408 - val_acc: 0.9715\n",
      "Epoch 167/250\n",
      " - 136s - loss: 0.0051 - acc: 0.9987 - val_loss: 0.2718 - val_acc: 0.9452\n",
      "Epoch 168/250\n",
      " - 136s - loss: 0.0077 - acc: 0.9981 - val_loss: 0.1833 - val_acc: 0.9529\n",
      "Epoch 169/250\n",
      " - 136s - loss: 0.0041 - acc: 0.9987 - val_loss: 0.1336 - val_acc: 0.9682\n",
      "Epoch 170/250\n",
      " - 136s - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1464 - val_acc: 0.9616\n",
      "Epoch 171/250\n",
      " - 136s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.1564 - val_acc: 0.9693\n",
      "Epoch 172/250\n",
      " - 136s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.2349 - val_acc: 0.9550\n",
      "Epoch 173/250\n",
      " - 136s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.1915 - val_acc: 0.9550\n",
      "Epoch 174/250\n",
      " - 136s - loss: 0.0063 - acc: 0.9979 - val_loss: 0.3235 - val_acc: 0.9287\n",
      "Epoch 175/250\n",
      " - 136s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2139 - val_acc: 0.9605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/250\n",
      " - 136s - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1495 - val_acc: 0.9704\n",
      "Epoch 177/250\n",
      " - 136s - loss: 5.4406e-04 - acc: 0.9999 - val_loss: 0.1549 - val_acc: 0.9704\n",
      "Epoch 178/250\n",
      " - 136s - loss: 0.0015 - acc: 0.9995 - val_loss: 0.1567 - val_acc: 0.9649\n",
      "Epoch 179/250\n",
      " - 136s - loss: 7.9567e-04 - acc: 0.9999 - val_loss: 0.1670 - val_acc: 0.9682\n",
      "Epoch 180/250\n",
      " - 136s - loss: 0.0020 - acc: 0.9994 - val_loss: 0.1858 - val_acc: 0.9682\n",
      "Epoch 181/250\n",
      " - 136s - loss: 9.5851e-04 - acc: 0.9998 - val_loss: 0.1630 - val_acc: 0.9704\n",
      "Epoch 182/250\n",
      " - 136s - loss: 0.0011 - acc: 0.9995 - val_loss: 0.1730 - val_acc: 0.9638\n",
      "Epoch 183/250\n",
      " - 136s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.1857 - val_acc: 0.9594\n",
      "Epoch 184/250\n",
      " - 136s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.2000 - val_acc: 0.9649\n",
      "Epoch 185/250\n",
      " - 136s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1912 - val_acc: 0.9682\n",
      "Epoch 186/250\n",
      " - 136s - loss: 0.0026 - acc: 0.9996 - val_loss: 0.1383 - val_acc: 0.9704\n",
      "Epoch 187/250\n",
      " - 136s - loss: 8.4225e-04 - acc: 0.9996 - val_loss: 0.1741 - val_acc: 0.9594\n",
      "Epoch 188/250\n",
      " - 136s - loss: 7.7998e-04 - acc: 0.9999 - val_loss: 0.1428 - val_acc: 0.9660\n",
      "Epoch 189/250\n",
      " - 136s - loss: 0.0031 - acc: 0.9987 - val_loss: 0.1829 - val_acc: 0.9616\n",
      "Epoch 190/250\n",
      " - 136s - loss: 0.0032 - acc: 0.9989 - val_loss: 0.1918 - val_acc: 0.9649\n",
      "Epoch 191/250\n",
      " - 136s - loss: 0.0066 - acc: 0.9981 - val_loss: 0.1654 - val_acc: 0.9583\n",
      "Epoch 192/250\n",
      " - 136s - loss: 0.0062 - acc: 0.9978 - val_loss: 0.1688 - val_acc: 0.9616\n",
      "Epoch 193/250\n",
      " - 136s - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1393 - val_acc: 0.9594\n",
      "Epoch 194/250\n",
      " - 136s - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1468 - val_acc: 0.9649\n",
      "Epoch 195/250\n",
      " - 136s - loss: 0.0093 - acc: 0.9970 - val_loss: 0.3603 - val_acc: 0.9167\n",
      "Epoch 196/250\n",
      " - 136s - loss: 0.0052 - acc: 0.9985 - val_loss: 0.2142 - val_acc: 0.9594\n",
      "Epoch 197/250\n",
      " - 136s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.2292 - val_acc: 0.9561\n",
      "Epoch 198/250\n",
      " - 136s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.1991 - val_acc: 0.9496\n",
      "Epoch 199/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9994 - val_loss: 0.1504 - val_acc: 0.9605\n",
      "Epoch 200/250\n",
      " - 136s - loss: 0.0023 - acc: 0.9991 - val_loss: 0.1128 - val_acc: 0.9660\n",
      "Epoch 201/250\n",
      " - 136s - loss: 4.5516e-04 - acc: 0.9999 - val_loss: 0.1229 - val_acc: 0.9682\n",
      "Epoch 202/250\n",
      " - 136s - loss: 6.1002e-04 - acc: 0.9998 - val_loss: 0.1369 - val_acc: 0.9649\n",
      "Epoch 203/250\n",
      " - 136s - loss: 0.0014 - acc: 0.9995 - val_loss: 0.1763 - val_acc: 0.9649\n",
      "Epoch 204/250\n",
      " - 136s - loss: 0.0023 - acc: 0.9991 - val_loss: 0.1757 - val_acc: 0.9649\n",
      "Epoch 205/250\n",
      " - 136s - loss: 0.0032 - acc: 0.9994 - val_loss: 0.1418 - val_acc: 0.9660\n",
      "Epoch 206/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.1445 - val_acc: 0.9682\n",
      "Epoch 207/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9994 - val_loss: 0.1655 - val_acc: 0.9649\n",
      "Epoch 208/250\n",
      " - 136s - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1810 - val_acc: 0.9616\n",
      "Epoch 209/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1559 - val_acc: 0.9671\n",
      "Epoch 210/250\n",
      " - 136s - loss: 0.0058 - acc: 0.9985 - val_loss: 0.1906 - val_acc: 0.9529\n",
      "Epoch 211/250\n",
      " - 136s - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1326 - val_acc: 0.9682\n",
      "Epoch 212/250\n",
      " - 136s - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1231 - val_acc: 0.9671\n",
      "Epoch 213/250\n",
      " - 136s - loss: 0.0035 - acc: 0.9985 - val_loss: 0.1578 - val_acc: 0.9605\n",
      "Epoch 214/250\n",
      " - 136s - loss: 0.0030 - acc: 0.9987 - val_loss: 0.1668 - val_acc: 0.9616\n",
      "Epoch 215/250\n",
      " - 136s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.1712 - val_acc: 0.9638\n",
      "Epoch 216/250\n",
      " - 136s - loss: 0.0033 - acc: 0.9988 - val_loss: 0.1664 - val_acc: 0.9671\n",
      "Epoch 217/250\n",
      " - 136s - loss: 0.0012 - acc: 0.9996 - val_loss: 0.1415 - val_acc: 0.9704\n",
      "Epoch 218/250\n",
      " - 136s - loss: 5.3405e-04 - acc: 0.9999 - val_loss: 0.1708 - val_acc: 0.9704\n",
      "Epoch 219/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1564 - val_acc: 0.9693\n",
      "Epoch 220/250\n",
      " - 136s - loss: 4.9683e-04 - acc: 1.0000 - val_loss: 0.1760 - val_acc: 0.9616\n",
      "Epoch 221/250\n",
      " - 136s - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1971 - val_acc: 0.9474\n",
      "Epoch 222/250\n",
      " - 136s - loss: 0.0075 - acc: 0.9976 - val_loss: 0.2094 - val_acc: 0.9638\n",
      "Epoch 223/250\n",
      " - 136s - loss: 0.0029 - acc: 0.9989 - val_loss: 0.1842 - val_acc: 0.9594\n",
      "Epoch 224/250\n",
      " - 136s - loss: 0.0011 - acc: 0.9996 - val_loss: 0.1523 - val_acc: 0.9704\n",
      "Epoch 225/250\n",
      " - 136s - loss: 3.0123e-04 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9715\n",
      "Epoch 226/250\n",
      " - 136s - loss: 0.0019 - acc: 0.9994 - val_loss: 0.1852 - val_acc: 0.9660\n",
      "Epoch 227/250\n",
      " - 136s - loss: 0.0034 - acc: 0.9993 - val_loss: 0.1958 - val_acc: 0.9649\n",
      "Epoch 228/250\n",
      " - 136s - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1496 - val_acc: 0.9594\n",
      "Epoch 229/250\n",
      " - 136s - loss: 0.0024 - acc: 0.9993 - val_loss: 0.1665 - val_acc: 0.9572\n",
      "Epoch 230/250\n",
      " - 136s - loss: 0.0079 - acc: 0.9972 - val_loss: 0.1598 - val_acc: 0.9682\n",
      "Epoch 231/250\n",
      " - 136s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.1544 - val_acc: 0.9649\n",
      "Epoch 232/250\n",
      " - 136s - loss: 7.2447e-04 - acc: 0.9998 - val_loss: 0.1669 - val_acc: 0.9660\n",
      "Epoch 233/250\n",
      " - 136s - loss: 0.0027 - acc: 0.9987 - val_loss: 0.1884 - val_acc: 0.9605\n",
      "Epoch 234/250\n",
      " - 136s - loss: 0.0040 - acc: 0.9993 - val_loss: 0.1952 - val_acc: 0.9572\n",
      "Epoch 235/250\n",
      " - 136s - loss: 0.0044 - acc: 0.9990 - val_loss: 0.1412 - val_acc: 0.9671\n",
      "Epoch 236/250\n",
      " - 136s - loss: 0.0022 - acc: 0.9993 - val_loss: 0.1793 - val_acc: 0.9583\n",
      "Epoch 237/250\n",
      " - 136s - loss: 0.0068 - acc: 0.9981 - val_loss: 0.2189 - val_acc: 0.9539\n",
      "Epoch 238/250\n",
      " - 136s - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1546 - val_acc: 0.9693\n",
      "Epoch 239/250\n",
      " - 136s - loss: 0.0015 - acc: 0.9994 - val_loss: 0.1413 - val_acc: 0.9649\n",
      "Epoch 240/250\n",
      " - 136s - loss: 0.0018 - acc: 0.9994 - val_loss: 0.2065 - val_acc: 0.9529\n",
      "Epoch 241/250\n",
      " - 136s - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1433 - val_acc: 0.9726\n",
      "Epoch 242/250\n",
      " - 136s - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1527 - val_acc: 0.9726\n",
      "Epoch 243/250\n",
      " - 136s - loss: 4.1606e-04 - acc: 1.0000 - val_loss: 0.1318 - val_acc: 0.9748\n",
      "Epoch 244/250\n",
      " - 136s - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1348 - val_acc: 0.9704\n",
      "Epoch 245/250\n",
      " - 136s - loss: 0.0177 - acc: 0.9943 - val_loss: 0.1605 - val_acc: 0.9649\n",
      "Epoch 246/250\n",
      " - 136s - loss: 0.0047 - acc: 0.9984 - val_loss: 0.1563 - val_acc: 0.9715\n",
      "Epoch 247/250\n",
      " - 136s - loss: 0.0014 - acc: 0.9995 - val_loss: 0.1492 - val_acc: 0.9715\n",
      "Epoch 248/250\n",
      " - 136s - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1492 - val_acc: 0.9693\n",
      "Epoch 249/250\n",
      " - 136s - loss: 9.1739e-04 - acc: 0.9996 - val_loss: 0.1309 - val_acc: 0.9748\n",
      "Epoch 250/250\n",
      " - 136s - loss: 3.5155e-04 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9781\n",
      "Test loss: 0.1162345795010368\n",
      "Test accuracy: 0.9780701754385965\n"
     ]
    }
   ],
   "source": [
    "model = inception_v4_backbone()\n",
    "plot_model(model, 'inceptionv4_classification_ORI_20200224_epoch250_shuffle.png', show_shapes=True)\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0, nesterov=False) #decay：每次更新後，學習速率隨之衰減的比率\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "model.summary();\n",
    "#history = model.fit(x=tr_img_data, y=tr_lbl_data, batch_size=32, epochs=150,verbose=2,shuffle=True,validation_split=0.1)\n",
    "history = model.fit(x=tr_img_data, y=tr_lbl_data, batch_size=32, epochs=250,verbose=2,shuffle=True,validation_data=(va_img_data,va_lbl_data))\n",
    "model.save('googlenetV4_classification_ORI_20200224_epoch250_shuffle.h5')\n",
    "\n",
    "# evaluate the model\n",
    "loss, acc = model.evaluate(va_img_data, va_lbl_data, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "  \n",
    "def isDisplayAvl():  \n",
    "    return 'DISPLAY' in os.environ.keys()  \n",
    "  \n",
    "import matplotlib.pyplot as plt  \n",
    "def plot_image(image):  \n",
    "    fig = plt.gcf()  \n",
    "    fig.set_size_inches(2,2)  \n",
    "    plt.imshow(image, cmap='binary')  \n",
    "    plt.show()    \n",
    "\n",
    "\n",
    "def show_train_history(history, tr_img_data, te_img_data):  \n",
    "    plt.plot(history.history[tr_img_data])  \n",
    "    plt.plot(history.history[te_img_data])  \n",
    "    plt.title('Train History')  \n",
    "    plt.ylabel(tr_img_data)  \n",
    "    plt.xlabel('Epoch')  \n",
    "    plt.legend(['train', 'validation'], loc='upper left')  \n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用函數 show_train_history 顯示 accuracy 在 train 與 evaluation 的差異\n",
    "#loss 在 train 與 evaluation 的差異\n",
    "from keras.utils import *  \n",
    "if isDisplayAvl():  \n",
    "    show_train_history(history, 'acc', 'val_acc')\n",
    "    show_train_history(history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, 'acc', 'val_acc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, 'loss', 'val_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6565/6565 [==============================] - ETA: 35 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 35s 5ms/step\n",
      "Training score: 7.338263583945313e-06\n",
      "Training accuracy: 1.0\n",
      "1642/1642 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 6ms/step\n",
      "Test score: 9.776649506052453e-06\n",
      "Test accuracy: 1.0\n",
      "6565/6565 [==============================] - ETA: 36 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 35s 5ms/step\n",
      "Training score: 7.767296922184451e-06\n",
      "Training accuracy: 1.0\n",
      "1642/1642 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 5ms/step\n",
      "Test score: 8.061299972361537e-06\n",
      "Test accuracy: 1.0\n",
      "6566/6566 [==============================] - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 35s 5ms/step\n",
      "Training score: 8.436645050247263e-06\n",
      "Training accuracy: 1.0\n",
      "1641/1641 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 5ms/step\n",
      "Test score: 5.3832712630331396e-06\n",
      "Test accuracy: 1.0\n",
      "6566/6566 [==============================] - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 35s 5ms/step\n",
      "Training score: 7.514802521973792e-06\n",
      "Training accuracy: 1.0\n",
      "1641/1641 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 5ms/step\n",
      "Test score: 9.071764276975457e-06\n",
      "Test accuracy: 1.0\n",
      "6566/6566 [==============================] - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 35s 5ms/step\n",
      "Training score: 8.073503945082997e-06\n",
      "Training accuracy: 1.0\n",
      "1641/1641 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 9s 5ms/step\n",
      "Test score: 6.836278126537113e-06\n",
      "Test accuracy: 1.0\n",
      "[100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "[100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "kfold =KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "tr_cvscores = []\n",
    "test_cvscores = []\n",
    "for ktrain, ktest in kfold.split(tr_img_data, tr_lbl_data):\n",
    "    #history = model.fit(x=tr_img_data[ktrain], y=tr_lbl_data[ktrain], batch_size=16, epochs=100,verbose=2,validation_split=0.2)\n",
    "    #model.save(str(times)+'_mosq-res34.h5')\n",
    "    #times=times+1\n",
    "    tr_score, tr_acc = model.evaluate(tr_img_data[ktrain],tr_lbl_data[ktrain])\n",
    "    print('Training score:', tr_score)\n",
    "    print('Training accuracy:', tr_acc)\n",
    "    tr_cvscores.append(tr_acc * 100)\n",
    "    test_score, test_acc = model.evaluate(tr_img_data[ktest],tr_lbl_data[ktest])\n",
    "    print('Test score:', test_score)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    test_cvscores.append(test_acc * 100)\n",
    "print(tr_cvscores)\n",
    "print(test_cvscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testdata():    \n",
    "#     test_imgs=[]    \n",
    "#     for root,dirs,files in os.walk(test_data): #讀取資料夾影像\n",
    "#         for f in files:\n",
    "#             img=cv2.imread(os.path.join(root,f))\n",
    "#             #print(os.path.join(root,f))\n",
    "#             img=cv2.resize(img,(299,299))\n",
    "#             img=img.reshape(-1, 299, 299, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
